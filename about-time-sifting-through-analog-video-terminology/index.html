<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>About Time: Sifting Through Analog Video Terminology - The Patch Bay</title><meta name="description" content="In case it's ever unclear, writing these blog posts is as much for me as it is for you, dear reader. Technical audiovisual and digital concepts are hard to wrap your head around, and for a myriad of reasons technical writing is frequently no help."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://test.patchbay.tech/about-time-sifting-through-analog-video-terminology/"><link rel="alternate" type="application/atom+xml" href="https://test.patchbay.tech/feed.xml"><link rel="alternate" type="application/json" href="https://test.patchbay.tech/feed.json"><meta property="og:title" content="About Time: Sifting Through Analog Video Terminology"><meta property="og:image" content="https://test.patchbay.tech/media/posts/25/series-8-title-sequence-clock-570x320.jpg"><meta property="og:image:width" content="570"><meta property="og:image:height" content="320"><meta property="og:site_name" content="The Patch Bay"><meta property="og:description" content="In case it's ever unclear, writing these blog posts is as much for me as it is for you, dear reader. Technical audiovisual and digital concepts are hard to wrap your head around, and for a myriad of reasons technical writing is frequently no help."><meta property="og:url" content="https://test.patchbay.tech//about-time-sifting-through-analog-video-terminology/"><meta property="og:type" content="article"><link rel="stylesheet" href="https://test.patchbay.tech/assets/css/style.css?v=e5ad27e7b330f5e7f7fa9bfb74e8fca4"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://test.patchbay.tech/about-time-sifting-through-analog-video-terminology/"},"headline":"About Time: Sifting Through Analog Video Terminology","datePublished":"2018-06-11T16:08-04:00","dateModified":"2024-11-09T11:37-05:00","image":{"@type":"ImageObject","url":"https://test.patchbay.tech/media/posts/25/series-8-title-sequence-clock-570x320.jpg","height":320,"width":570},"description":"In case it's ever unclear, writing these blog posts is as much for me as it is for you, dear reader. Technical audiovisual and digital concepts are hard to wrap your head around, and for a myriad of reasons technical writing is frequently no help.","author":{"@type":"Person","name":"Ethan","url":"https://test.patchbay.tech/authors/ethan/"},"publisher":{"@type":"Organization","name":"Ethan"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><header class="top js-header"><a class="logo" href="https://test.patchbay.tech/">The Patch Bay</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://test.patchbay.tech/submission-box/" target="_self">Submission Box</a></li><li><a href="https://test.patchbay.tech/about-the-creator/" target="_self">About</a></li></ul></nav></header><main class="post"><article class="content"><div class="hero"><header class="hero__content"><div class="wrapper"><h1>About Time: Sifting Through Analog Video Terminology</h1><div class="feed__meta content__meta"><a href="https://test.patchbay.tech/authors/ethan/" class="feed__author">Ethan</a> <time datetime="2018-06-11T16:08" class="feed__date">June 11, 2018</time></div></div></header><figure class="hero__image"><div class="hero__image-wrapper"><img src="https://test.patchbay.tech/media/posts/25/series-8-title-sequence-clock-570x320.jpg" srcset="https://test.patchbay.tech/media/posts/25/responsive/series-8-title-sequence-clock-570x320-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/series-8-title-sequence-clock-570x320-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/series-8-title-sequence-clock-570x320-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/series-8-title-sequence-clock-570x320-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/series-8-title-sequence-clock-570x320-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/series-8-title-sequence-clock-570x320-2xl.webp 1920w" sizes="88vw" loading="eager" height="320" width="570" alt=""></div></figure></div><div class="entry-wrapper content__entry"><p>In case it's ever unclear, writing these blog posts is as much for me as it is for you, dear reader. Technical audiovisual and digital concepts are hard to wrap your head around, and for a myriad of reasons technical writing is frequently no help. Writing things out, as clearly and simply as I can, is as much a way of self-checking that I actually understand what's going on as it is a primer for others.</p><p>And it case this intro is unclear, this is a warning to cover my ass as I dive into a topic that still trips me up every time I try to walk through it out loud. I'll provide references as I can at the end of the piece, but listen to me at your own risk.</p><p>When I first started learning about preserving analog video, *most* of what I was reading/talking about made a certain amount of sense, which is to say it at least translated into some direct sensory/observable phenomenon - luminance values made images brighter or darker, mapping audio channels clearly changed how and what I was hearing, using component video rather than composite meant mucking around with a bunch more <a href="https://amiaopensource.github.io/cable-bible/">cables</a>. But when we talked about analog signal workflows, there always seemed to be three big components to keep track of: video (what I was seeing), audio (what I was hearing) and then this nebulous goddamn thing called "sync" that I didn't understand at all but seemed very very important.</p><figure class="wp-image-3275"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/tongue-1024x923.jpg" alt="" width="475" height="428" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/tongue-1024x923-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/tongue-1024x923-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/tongue-1024x923-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/tongue-1024x923-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/tongue-1024x923-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/tongue-1024x923-2xl.webp 1920w"></figure>The same way I feel when anyone tells me "umami" is a thing WHAT ARE YOU<p></p><p>I do not know who to blame for the morass of analog video signal terms and concepts that all have to do in some form with "time" and/or "synchronization". Most likely, it's just an issue at the very heart of the technology, which is such a marvel of mechanical and mathematical precision that even as OLED screens become the consumer norm I'm going to be right here crowing about how incredible it is that CRTs ever are/were a thing. What I do know is that between the glut of almost-but-not-quite-the-same words and devices that do almost-but-not-quite-the-same-thing-except-when-they're-combined-and-then-they-DO-do-the-same-thing, there's a real hindrance to understanding how to put together or troubleshoot an analog video digitization setup. Much of both the equipment and the vocabulary that we're working with came from the needs of production, and that has led to some redundancies that don't always make sense coming from the angle of either preservation or casual use.</p><figure class="wp-image-3280"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/time-1024x576.jpg" alt="" width="508" height="286" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/time-1024x576-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/time-1024x576-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/time-1024x576-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/time-1024x576-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/time-1024x576-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/time-1024x576-2xl.webp 1920w"></figure>I once digitized an audio cassette from the '70s on which an audio tech was testing levels (...I hope?) by just repeating "time time time time" about 100 times in a row and ever since that day I've feared that his unleashed soul now possesses me. Anyway.<p></p><p>So I'm going to offer a guide here to some concepts and equipment that I've frequently seen either come up together or understandably get confused for each other. That includes in particular:</p><ul><li>sync and sync generators</li><li>time base correction</li><li>genlock</li><li>timecode</li></ul><p>...though other terms will inevitably rise as we go along. I'm going to assume a certain base level of knowledge with the characteristics and function of analog video signal - that is, I will write assuming the reader has been introduced to electron guns, lines, fields, frames, interlacing, and the basics of reading a classic/default analog video waveform. But I will try not to ever go right into the deep end.</p><h3>Sync/Sync Generators</h3><figure class="aligncenter size-medium wp-image-3276"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/blackmagic-mini-converter-sync-generator-300x250.jpg" alt="" width="300" height="250" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/blackmagic-mini-converter-sync-generator-300x250-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/blackmagic-mini-converter-sync-generator-300x250-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/blackmagic-mini-converter-sync-generator-300x250-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/blackmagic-mini-converter-sync-generator-300x250-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/blackmagic-mini-converter-sync-generator-300x250-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/blackmagic-mini-converter-sync-generator-300x250-2xl.webp 1920w"></figure><p>I know I just said I would assume some analog video knowledge, but let's take a moment to contemplate the basics, because it helps me wrap my head around sync generators and why they can be necessary.</p><p>Consider the NTSC analog video standard (developed in the United States and employed in North, Central and parts of South America). According to NTSC, every frame of video has two fields, each consisting of 262.5 scan lines - so that's 525 scan lines per frame. There are also 29.97 frames of video per second.</p><p>That means the electron gun in a television monitor has to fire off 15734.25 lines of video <strong>PER SECOND</strong> - and that includes not just actually tracing the lines themselves, but the time it takes to reset both horizontally (to start the next line) and vertically (to start the next field).</p><p>[embed]https://www.youtube.com/watch?v=3BJU2drrtCM&t=16s[/embed]</p><p>Now throw a recording device into the mix. At the same time that a camera is creating that signal and a monitor is playing it back, a VTR/VCR has to receive that signal and translate it into a magnetic field stored on a constantly-moving stretch of videotape via an insanely quick-spinning metal drum.</p><p>Even in the most basic of analog video signal flows, there are multiple devices (monitor, playback/recording device, camera, etc.) here that need to have an extremely precise sense of timing. The recording device, for instance, needs to have a very consistent internal sense of how long a second is, in order for all its tiny little metal and plastic pieces to spin and roll and pulse in sync (for a century, electronic devices, either analog OR digital, have used tiny pieces of <a href="https://en.wikipedia.org/wiki/Crystal_oscillator">vibrating crystal quartz</a> to keep track of time - which is just a whole other insane tangent). But, in order to achieve the highest quality signal flow, it also needs to have the <strong>exact</strong> <strong>same</strong> <strong>sense</strong> of how long a second is as the camera and the monitor that it's also hooked up to.</p><p>When you're dealing with physical pieces of equipment, possibly manufactured by completely different companies at completely different times from completely different materials, that's difficult to achieve. Enter in sync signal and sync generators.</p><figure class="wp-image-3284"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/bunny-1024x576.png" alt="" width="450" height="253" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/bunny-1024x576-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/bunny-1024x576-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/bunny-1024x576-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/bunny-1024x576-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/bunny-1024x576-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/bunny-1024x576-2xl.webp 1920w"></figure>Stay with me here<p></p><p>Sync generators essentially serve as a drumbeat for an analog video system, pumping out a trusted reference signal that all other devices in the signal chain can use to drive their work instead of their own internal sense of timing. There are two kinds of sync signals/pulses that sync generators have historically output:</p><p><strong>Drive pulses</strong> were almost exclusively used to trigger certain circuits in tube cameras, and were never part of any broadcast/recorded video signal. So you're almost certainly never going to need to use one in archival digitization work, but just in case you ever come across a sync generator with V. Drive and H. Drive outputs (vertical drive and horizontal drive pulses), that's what those are for.</p><p><strong>Blanking pulses</strong> cause the electron gun on a camera or monitor to go into its "blanking" period - which is the point at which the electron gun briefly shuts off and retraces back to the beginning of a new line (horizontal blanking) or of a new field (vertical blanking). These pulses are a part of every broadcast/recorded video signal, and they must be extremely consistent to maintain the whole 525-scan-lines-29.97-times-per-second deal.</p><p>Since blanking pulses are the vast majority of modern sync signals, you may also just see these referred to as "sync pulses".</p><p>So the goal of sync generators is to output a constant video signal with precise blanking pulses that are trusted to be exactly where (or to be more accurate, <em>when</em>) they should be. Blanking pulses are contained in the "inactive" part of a video signal, meaning they are never meant to actually be visualized as image on a video camera or monitor (unless for troubleshooting purposes) - so it literally does not matter what the "active" part of a sync generator's video signal is. It could just be field after field, frame after frame of black (often labeled "black burst").  It could be some kind of test pattern - so you will often see test pattern generators that double as or are used as sync generators, even though these are separate functions/purposes, and thus could also be entirely separate devices in your setup.</p><figure><a href="https://test.patchbay.tech/media/posts/25/colour-bars-smpte-75-640x480.gif"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/colour-bars-smpte-75-640x480.gif" width="451" height="338"></a></figure>Color bars - not *just* for geeky yet completely hard-to-use desktop wallpapers<p></p><p>(To belabor the point, test patterns, contained in the "active" part of the video signal, can be used to <span style="text-decoration: underline;">check</span> the system, but they do not <span style="text-decoration: underline;">drive</span> the system in the same way that the blanking pulses in the "inactive" part of a signal do. IMHO, this is an extremely misleading definition of "active" and "inactive", since both parts are clearly serving crucial roles to the signal, and what is meant is just "seen" or "unseen".)</p><p>Here's the kicker - strictly speaking, sync generators <em>aren't absolutely necessary to a digitization station</em>. It's entirely possible that you'll hook up all your components and all the individual pieces of equipment will work together acceptably - their sense of where and when blanking pulses should fall might already be the same, or close enough to be negligible.</p><p>But maybe you're seeing some kind of  <a href="https://bavc.github.io/avaa/artifacts/sync_loss.html">a wobbling or inconsistent image.</a> That *could* be a sync issue, with one of your devices (the monitor, e.g.) losing its sense of proper timing, and resolvable by making sure all devices are working off the same, trusted sync generator.</p><p>You'll see inputs for sync signal labeled in all sorts of inconsistent ways on analog video devices: "Sync In", "Ext Sync", "Ext Ref", "Ref In", etc. As far as I'm aware, these all mean the same thing, and references in manuals or labels to "sync signal" or "reference signal" should be treated interchangeably.</p><h3>Time Base Correction</h3><figure class="aligncenter wp-image-3277"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/tbc.jpg" alt="" width="493" height="370" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/tbc-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/tbc-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/tbc-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/tbc-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/tbc-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/tbc-2xl.webp 1920w"></figure><p>Sync generators can help line up devices with inconsistent timing in a system as a video signal is passed from one to another. Time Base Correctors (TBCs) perform an extremely similar but ever-so-confusingly-different task. TBCs can take an input video signal, strip out inconsistent sync/blanking pulses, and replace them entirely with new, steady ones.</p><p>This is largely necessary when dealing with pre-recorded signals. Consider a perfectly set up, synced recording system: using a CRT for the operator to monitor the image, a video camera passed a video signal along to a VTR, which recorded that signal on to magnetic tape. At the time, a sync generator made sure all these devices worked together seamlessly. But now, playing back that tape for digitization, we've introduced the vagaries of magnetic tape's physical/chemical makeup into the mix. Perhaps it's been years and the tape has stretched or bent, the metallic particles have expanded or compressed - not enough to prevent playback, but enough to muck with the sync pulses that rely on precision down to millionths of a second. As described with sync loss above, this usually manifests in the image looking wobbly, improperly framed or distorted on a monitor, etc.</p><figure class="size-large"><a href="https://bavc.github.io/avaa/artifacts/time_base_error.html"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/FlagwavingSkewErrorTearing.png" width="511" height="159" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/FlagwavingSkewErrorTearing-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/FlagwavingSkewErrorTearing-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/FlagwavingSkewErrorTearing-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/FlagwavingSkewErrorTearing-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/FlagwavingSkewErrorTearing-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/FlagwavingSkewErrorTearing-2xl.webp 1920w"></a></figure><a href="https://bavc.github.io/avaa/artifacts/time_base_error.html">https://bavc.github.io/avaa/artifacts/time_base_error.html</a><p></p><p>TBCs can either use their own internal sense of time to replace/correct the timing of the sync pulses on the recorded video signal - or they can use the drumbeat of a sync generator as a reference, to ensure consistency within a whole system of devices.</p><p><em>(Addendum): </em>A point I'm still not totally clear on is the separation (or lack thereof) between time base correction and <strong>frame synchronization</strong>. According to the following video I found, a stand-alone <strong>frame synchronizer</strong> could stabilize the vertical blanking pulses in a signal only, resulting in a solid image at the moment of transition from one frame to another (that is, the active video image remains properly centered vertically within a monitor), but did nothing for horizontal sync pulses, potentially resulting in line-by-line inconsistencies:</p><p>[embed]https://www.youtube.com/watch?v=zC5OIWx9byg[/embed]</p><p>So time base correction would appear to <em>incorporate</em> frame synchronization, while adding the extra stabilization of consistent horizontal sync/blanking pulses.</p><p>While, as I said above, you can very often get away with digitizing video without a sync generator, TBCs are generally much more critical. It depends on what analog video format you're working with exactly, but whereas the nature of analog devices meant there was ever so slight leeway to deal with those millionth-of-a-second inconsistencies (say, to display a signal on a CRT), the precise on-or-off, one-or-zero nature of digital signals means analog-to-digital converters usually need a very very steady signal input to do their job properly.</p><p>You may however not need an <em>external</em> TBC unit. Many video playback decks had them built in, though of varying quality and performance. If you can, check the manual for your model(s) to see if it has an internal TBC, and if so, if it's possible to adjust or even turn it off if you have a more trustworthy external unit.</p><figure class="size-full wp-image-3281"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/s-vhs_with-tbc.jpg" alt="" width="800" height="526" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/s-vhs_with-tbc-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/s-vhs_with-tbc-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/s-vhs_with-tbc-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/s-vhs_with-tbc-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/s-vhs_with-tbc-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/s-vhs_with-tbc-2xl.webp 1920w"></figure>Professional-quality S-VHS deck with built-in TBC controls<p></p><p>Technically there are actually three kinds of TBCs: line, full frame and full field. <strong>Line TBC</strong>s can only sample, store and correct errors/blanking pulses for a few lines of video at a time. <strong>Full field TBC</strong>s can handle, as the name implies, a full 262.5 (NTSC) lines of video at a time, and <strong>full frame TBC</strong>s can take care a whole frame's worth (525, NTSC) of lines at a time. "Modern", late-period analog TBCs are pretty much always going to be full frame, or even capable of multiple frames' worth of correction at a time (this is good for avoiding delay and sync issues in the <em>system</em> if working without a sync generator). This will likely only come into play with older TBC units.</p><p>And here's one last thing that I found confusing about TBCs given the particular equipment I was trained on: this process of time base correction, and TBCs themselves, has nothing to do with adjusting the qualities of the active image itself. Brightness, saturation, hue - these visible characteristics of video image are adjusted using a device called a <strong>processing amplifier</strong> or <strong>proc amp</strong>.</p><figure class="aligncenter wp-image-3282"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/dps_tbc-1024x768.jpg" alt="" width="584" height="438" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/dps_tbc-1024x768-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/dps_tbc-1024x768-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/dps_tbc-1024x768-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/dps_tbc-1024x768-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/dps_tbc-1024x768-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/dps_tbc-1024x768-2xl.webp 1920w"></figure><p>Because the process of replacing or adjusting sync pulses is a natural moment in a signal flow to ALSO adjust active video signal levels (may as well do all your mucking at once, to limit troubleshooting if something's going wrong), many external TBC units also contain proc amps, thus time base correction and video adjustments are made on the same device, such as the DPS TBC unit above. But there are two different parts/circuit boards of the unit that are doing these two tasks, and they can be housed in completely separate devices as well (i.e. you may have a proc amp that does no time base correction, or a TBC that offers no signal level adjustments).</p><h3>Genlock</h3><figure class="aligncenter wp-image-3278"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/genlock-1024x801.jpg" alt="" width="475" height="371" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/genlock-1024x801-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/genlock-1024x801-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/genlock-1024x801-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/genlock-1024x801-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/genlock-1024x801-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/genlock-1024x801-2xl.webp 1920w"></figure><p>"Genlock" is a phrase and label that you may see on various devices like TBCs, proc amps, special effects generators and more - often instead of or in the same general place you would see "Sync" or "Ref" inputs. What's the deal here?</p><p>This term really grew out of the production world and was necessary for cases where editors or broadcasters were trying to mix two or more input video signals into one output. When mixing various signals, it was again good/recommended practice to choose one as the timing reference - all the other input signals, output, and special effects created (fades, added titles, wipes, etc. etc.) would be "locked" on to the timing of the chosen genlock input (which might be either a reference signal from a sync generator, or one of the actually-used video inputs). This prevented awkward "jumps" or other visual errors when switching between or mixing the multiple signals.</p><p>In the context of a more straightforward digitization workflow, where the goal is not to mix multiple signals together but just pass one steadily all the way through playback and time base correction to monitoring and digitization, "genlock" can be treated as essentially interchangeable with the sync signal we discussed in the "Sync/Sync Generators" section above. If the device you're using has a genlock input, and you're employing a sync generator to provide an external timing reference for your system, this is where you would connect the two.</p><h3>Timecode</h3><figure class="aligncenter wp-image-3279"><img loading="lazy" src="https://test.patchbay.tech/media/posts/25/timecode_reader.jpeg" alt="" width="468" height="350" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://test.patchbay.tech/media/posts/25/responsive/timecode_reader-xs.webp 640w, https://test.patchbay.tech/media/posts/25/responsive/timecode_reader-sm.webp 768w, https://test.patchbay.tech/media/posts/25/responsive/timecode_reader-md.webp 1024w, https://test.patchbay.tech/media/posts/25/responsive/timecode_reader-lg.webp 1366w, https://test.patchbay.tech/media/posts/25/responsive/timecode_reader-xl.webp 1600w, https://test.patchbay.tech/media/posts/25/responsive/timecode_reader-2xl.webp 1920w"></figure><p>The signals and devices that I've been describing have been all about driving machinery - time base is all about coordinating mechanical and electrical components that function down at the level of milliseconds.</p><p>Timecode, on the other hand, is for people. It's about identifying frames of video for the purpose of editing, recording or otherwise manipulating content. Unlike film, where if absolutely need be a human could just look at and individually count frames to find and edit images on a reel, magnetic tape provides no external, human-readable sense of what image or content is located where. Timecode provides that. SMPTE timecode, probably the most commonly used standard, identified frames according to a clock-based system formatted "00:00:00:00", which translated to "Hours:Minutes:Seconds:Frames".</p><p>Timecode could be read, generated, and recorded by most playback/recording/editing devices (cameras or VTRs), but there were also stand-alone timecode reader/generator boxes created (such as in the photo above) for consistency and stability's sake across multiple recording devices in a system.</p><p>There have been multiple systems of recording and deploying timecode throughout the history of video, depending on the format in question and other concerns. Timecode was sometimes recorded as its own signal/track on a videotape, entirely separate from the video signal, in the same location as one might record an audio track. This system was called <strong>Linear Timecode (LTC)</strong>. The problem with LTC was, like with audio tracks, the tape had to be in constant motion to read the timecode track (like how you can not keep hearing an audio signal when you pause it, even though you *can* potentially keep seeing one frame of image when a video signal is paused on one line).</p><p><strong>Vertical Interval Timecode (VITC)</strong> fixed this (and had the added benefit of freeing up more physical space on the tape itself) by incorporating timecode into video signal itself, in a portion of the inactive, blanking part of the signal. This allowed systems to read/identify frame numbers even when the tape was paused.</p><p>Other systems like <strong>CTL timecode</strong> (control track) and <strong>BITC </strong>(timecode burnt-in to the video image) were also developed, but we don't need to go too far into that here.</p><p>As long as we're at it, however, I'd also like to quickly clarify two more terms: <strong>drop-frame</strong> and <strong>non-drop-frame timecode</strong>. These came about from a particular problem with the NTSC video standard (as far as I'm aware, PAL and SECAM do not suffer the same, but please someone feel free to correct me). Since NTSC video plays back at the frustratingly non-round number of 29.97 frames per second (a number arrived at for mathematical reasons beyond my personal comprehension that have something to do with how the signal carries color information), the timecode identifying frame numbers will eventually drift away from "actual" clock time as perceived/used by humans. An "hour of timecode" which by necessity must count upwards at a 30 fps rate such as:</p><p>00:00:00:28 00:00:00:29 00:00:01:00 00:00:01:01</p><p>played back at 29.97 fps, will actually be 3.6 seconds <em>longer</em> than "wall-clock" time.</p><p>That's already an issue at an hour, and proceeds to get worse the longer the content being recorded. So SMPTE developed "drop-frame" timecode, which confusingly <em>does not drop actual frames of video!!</em> Instead, it drops some of the <em>timecode frame markers</em>. Using drop-frame timecode, our sequence would actually proceed thus:</p><p>00:00:00;28 00:00:00;29 00:00:01;02 00:00:01;03</p><p>With the ":00" and ":01" frame markers removed entirely from the timecode; <em>except for every tenth minute</em>, when they are re-inserted to make the math check out:</p><p>00:00:09;28 00:00:09;29 00:00:10;00 00:00:10;01</p><p>Non-drop-frame timecode simply proceeds as normal, with the potential drift from clock time. Drop-frame timecode is often (but not necessarily - watch out) identified in video systems using semi-colons or single periods instead of colons between the second and frame counts, as I have done above. Semi-colons are common on digital devices, while periods are common on VTRs that didn't have the ability to display semi-colons.</p><p>I hope this journey through the fourth dimension of analog video clarifies a few things. While each of these concepts is reasonable enough on their own, the way they relate to each other is not always clear, and the similarity in terms can send your brain down the wrong alley quickly. Happy digitizing!</p><h6>Resources</h6><p>Andre, Adam. "Time Base Corrector<em>."</em> Written for NYU-MIAP course in Video Preservation I, Fall 2017. Accessed 6/9/2018. <a href="https://web.archive.org/web/20201028020601/https://www.nyu.edu/tisch/preservation/program/student_work/2017fall/17f_3403_Andre_a1.pdf">https://www.nyu.edu/tisch/preservation/program/student_work/2017fall/17f_3403_Andre_a1.pdf</a></p><p>"Genlock: What is it and why is it important?" Worship IMAG blog. Posted 6/11/2011. Accessed 6/8/2018. <a href="https://web.archive.org/web/20160727090202/https://worshipimag.com/2011/06/11/gen-lock-what-is-it-and-why-is-it-important/">https://worshipimag.com/2011/06/11/gen-lock-what-is-it-and-why-is-it-important/</a></p><p>Marsh, Ken. <span style="text-decoration: underline;">Independent Video.</span> San Francisco, CA: Straight Arrow Books, 1974.</p><p>Poynton, Charles. <span style="text-decoration: underline;">Digital Video and HD: Algorithms and Interfaces</span>. 2nd edition. Elsevier Science, 2012.</p><p><a href="https://en.wikipedia.org/wiki/SMPTE_timecode">SMPTE timecode</a>. Wikipedia. Accessed 6/8/2018.</p><p>Weise, Marcus and Diana Weynand. <span style="text-decoration: underline;">How Video Works: From Analog to High Definition</span>. 2nd Edition. Burlington, MA: Focal Press, 2013.</p></div><footer class="content__footer"><div class="entry-wrapper"><p class="content__updated">This article was updated on November 9, 2024</p><div class="content__actions"><ul class="content__tag"><li><a href="https://test.patchbay.tech/tags/video-preservation/">Video Preservation</a></li></ul><div class="content__share"><button class="btn--icon content__share-button js-content__share-button"><svg width="20" height="20" aria-hidden="true"><use xlink:href="https://test.patchbay.tech/assets/svg/svg-map.svg#share"></use></svg> <span>Share It</span></button><div class="content__share-popup js-content__share-popup"></div></div></div><div class="content__bio bio"><div><h3 class="h4 bio__name"><a href="https://test.patchbay.tech/authors/ethan/" rel="author">Ethan</a></h3></div></div></div><nav class="content__nav"><div class="wrapper"><div class="content__nav-inner"><div class="content__nav-prev"><a href="https://test.patchbay.tech/a-guide-to-legacy-mac-emulators/" class="content__nav-link" rel="prev"><figure class="content__nav-image"><img src="https://test.patchbay.tech/media/posts/22/responsive/sad-mac-xs.webp" class="lazyload" loading="lazy" alt="" height="375" width="375"></figure><div><span>Previous</span> A Guide to Legacy Mac Emulators</div></a></div><div class="content__nav-next"><a href="https://test.patchbay.tech/doing-digipres-with-windows/" class="content__nav-link" rel="next"><div><span>Next</span> Doing DigiPres with Windows</div><figure class="content__nav-image"><img src="https://test.patchbay.tech/media/posts/21/responsive/windows-logo-xs.webp" class="lazyload" loading="lazy" alt="" height="900" width="900"></figure></a></div></div></div></nav></footer></article><div class="content__related related"><div class="wrapper"><h2 class="h4 related__title">You should also read:</h2><article class="feed__item feed__item--centered"><figure class="feed__image related__image"><img src="https://test.patchbay.tech/media/posts/29/snr.png" srcset="https://test.patchbay.tech/media/posts/29/responsive/snr-xs.webp 640w, https://test.patchbay.tech/media/posts/29/responsive/snr-sm.webp 768w, https://test.patchbay.tech/media/posts/29/responsive/snr-md.webp 1024w" sizes="(min-width: 600px) calc(4.38vw + 143px), 87.86vw" loading="lazy" height="297" width="492" alt=""></figure><div class="feed__content"><header><div class="feed__meta"><a href="https://test.patchbay.tech/authors/ethan/" class="feed__author">Ethan</a> <time datetime="2020-02-07T19:36" class="feed__date">February 7, 2020</time></div><h3 class="feed__title"><a href="https://test.patchbay.tech/a-brief-introduction-to-signal-to-noise-ratio-for-analog-video-preservation/">A Brief Introduction to Signal-to-Noise Ratio for Analog Video Preservation</a></h3></header><p>This is a guest post written by Jeff Lauber, based on his paper originally written for a course on “Video Preservation” in NYU’s M.A. program in Moving Image Archiving and Preservation. Jeff is a media archivist based in New York City. He currently works as&hellip;</p><a href="https://test.patchbay.tech/a-brief-introduction-to-signal-to-noise-ratio-for-analog-video-preservation/" class="readmore feed__readmore">Continue reading...</a></div></article><article class="feed__item feed__item--centered"><figure class="feed__image related__image"><img src="https://test.patchbay.tech/media/posts/27/Maxell-blown-away-1.jpg" srcset="https://test.patchbay.tech/media/posts/27/responsive/Maxell-blown-away-1-xs.webp 640w, https://test.patchbay.tech/media/posts/27/responsive/Maxell-blown-away-1-sm.webp 768w, https://test.patchbay.tech/media/posts/27/responsive/Maxell-blown-away-1-md.webp 1024w" sizes="(min-width: 600px) calc(4.38vw + 143px), 87.86vw" loading="lazy" height="406" width="754" alt=""></figure><div class="feed__content"><header><div class="feed__meta"><a href="https://test.patchbay.tech/authors/ethan/" class="feed__author">Ethan</a> <time datetime="2018-09-29T15:33" class="feed__date">September 29, 2018</time></div><h3 class="feed__title"><a href="https://test.patchbay.tech/see-what-you-hear-audio-calibration-for-video-digitization/">See What You Hear: Audio Calibration for Video Digitization</a></h3></header><p>I've always been amused by the way a certain professional field frequently goes out of its way to shout "we don't understand audio" to the world. (Association of Moving Image Archivists, Moving Image Archiving and Preservation, Moving Image Archive Studies, Museum of the Moving Image,&hellip;</p><a href="https://test.patchbay.tech/see-what-you-hear-audio-calibration-for-video-digitization/" class="readmore feed__readmore">Continue reading...</a></div></article><article class="feed__item feed__item--centered"><figure class="feed__image related__image"><img src="https://test.patchbay.tech/media/posts/15/img_2841.jpg" srcset="https://test.patchbay.tech/media/posts/15/responsive/img_2841-xs.webp 640w, https://test.patchbay.tech/media/posts/15/responsive/img_2841-sm.webp 768w, https://test.patchbay.tech/media/posts/15/responsive/img_2841-md.webp 1024w" sizes="(min-width: 600px) calc(4.38vw + 143px), 87.86vw" loading="lazy" height="2448" width="3264" alt=""></figure><div class="feed__content"><header><div class="feed__meta"><a href="https://test.patchbay.tech/authors/ethan/" class="feed__author">Ethan</a> <time datetime="2017-03-02T12:10" class="feed__date">March 2, 2017</time></div><h3 class="feed__title"><a href="https://test.patchbay.tech/upgrading-video-digitization-stations/">Upgrading Video Digitization Stations</a></h3></header><p>In the primary MIAP lab we have four Mac Pro stations set up mainly for video digitization and capture. They get most heavily used during our two Video Preservation courses: Video Preservation I, which focuses on technical principles and practice of digitization from analog video&hellip;</p><a href="https://test.patchbay.tech/upgrading-video-digitization-stations/" class="readmore feed__readmore">Continue reading...</a></div></article></div></div></main><footer class="footer footer--glued"><div class="wrapper"><div class="footer__copyright"><p>Powered by Publii</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg width="20" height="20"><use xlink:href="https://test.patchbay.tech/assets/svg/svg-map.svg#toparrow"/></svg></button></div></footer><script defer="defer" src="https://test.patchbay.tech/assets/js/scripts.min.js?v=ffcbea6c02c8178d10092962b235a5b0"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>